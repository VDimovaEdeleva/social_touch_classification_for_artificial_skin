clear all;
clc; clear; 
close all;
% author : Vanessa Page
% January 2019

%% PART 1: build matrix with true labels for gestures, called "targetGestures" 
% need to build the matrix with binary labels because that's the format the
% MATLAB NN Pattern Recognition app needs the data in. 
% Format is such that for there is a 1 for the index of [gesture class label, trial]

%first make label matrix for 1 subject's data
% 10 rows for each gesture, 100 columns for each trial. Put a 1 for label,
% everything else is zeros 

targetGestures = zeros(10,100); 
for i = 1:10
    for j = (i-1)*10+1:i*10
        targetGestures(i,j) = 1; 
    end
end

% make the same label matrix for other subjects
tmpTargetGestures = zeros(10,100); 
for i = 1:10
    for j = (i-1)*10+1:i*10
        tmpTargetGestures(i,j) = 1;
    end
end

% take label matrix for 1 subject, repeat it for each subject, and
% cocatonate them 

nbParticipants = 21; 
for i = 1 :nbParticipants-1
    targetGestures = [targetGestures, tmpTargetGestures];
end

targetGesturesClass = NaN(1,length(targetGestures));
for j=1:size(targetGestures,2)
    for i=1:size(targetGestures,1)
        if targetGestures(i,j) == 1
            targetGesturesClass(j) = i;
        end
    end
end
  

% edit feature matrix 
featureInputsOriginal = load('feature_mat_subj_1-21.mat');
featureInputsOriginal = featureInputsOriginal.feature_mat;
featureInputsOriginal = featureInputsOriginal'; %transpose matrix so it fits the label matrix 
% delete the first 3 rows that have the labels for participant number,
% gesture number, and trial 
featureInputsOriginal([1,2,3],:) = [];

%% PART 2: change the feature matrix and the label matrix to include only portions of the total data

% ==========change this number for each iteration of calculating precision,
% recall, accuracy, and F score with different amounts of data included for training============
nbTrainSubjects=20;

for i=1:nbTrainSubjects        %size(featureInputsOriginal,2)/100  
%     filenameTrain = strcat('featureInputsTrain_', num2str(i), '.mat');
%     filenameTest = strcat('featureInputsTest_', num2str(i), '.mat');    
    featureInputsTrain   = featureInputsOriginal(:,1:i*100);                %We train the NN with this
    featureInputsTest    = featureInputsOriginal(:,(i*100)+1:end);          %We generate predictions for this array using the NN matlab code generated by the GUI
%     save(filenameTrain, 'featureInputsTrain');
%     save(filenameTest, 'featureInputsTest');
    targetGesturesTrain = targetGestures(:,1:i*100);                        %We need this to train NN model (labels for our data)
    targetGesturesTest = targetGestures(:,(i*100)+1:end);                   
    targetGesturesClassTrain = targetGesturesClass(:,1:i*100);
    targetGesturesClassTest = targetGesturesClass(:,(i*100)+1:end);         %We need this to get precision and recall of the testing data on the NN code 
end


%% change this number myNeuralNetworkFunction_x where x is the number of subject inluded in training data 
% =============================================

% myNeuralNetworkFunction is the function outputted by the GUI
resultsProb = myNeuralNetworkFunction_20(featureInputsTest);                %CHANGE THE NN TO BE THE CURRENTLY TRAINED ONE
resultsClass = NaN(1,size(resultsProb,2));
resultsMaxProb = max(resultsProb,[],1);

for j=1:size(resultsProb,2)
    for i=1:size(resultsProb,1)
        if resultsProb(i,j) == resultsMaxProb(j) 
            resultsClass(j) = i;
        end
    end
end

% calculate number of correct predictions from NN to calculate % accuracy 
nbCorrect = 0;
for i=1:length(resultsClass)
    if(resultsClass(i)==targetGesturesClassTest(i)) 
        nbCorrect=nbCorrect+1;
    end    
end

accuracyRate = nbCorrect/length(resultsClass);
errorRate = 1-accuracyRate;

%% plot precision and recall for increasing amount of data

nbGestures = 10;
TP = zeros(1,nbGestures); % TP = true positives
FP = zeros(1,nbGestures); % FP = false positives
FN = zeros(1,nbGestures); % FN = false negatives 
precision = NaN(1,nbGestures);
recall = NaN(1,nbGestures);
F1Score = NaN(1,nbGestures);
for g=1:nbGestures % calculate TP, FP, and FN for each class of gestures, which will later be averaged
   for i=1:length(resultsClass)
        if(resultsClass(i)==g && targetGesturesClassTest(i)==g) 
            TP(g)=TP(g)+1;
        end 
        
        if(resultsClass(i)==g && targetGesturesClassTest(i)~=g) 
            FP(g)=FP(g)+1;
        end
        
        if(resultsClass(i)~=g && targetGesturesClassTest(i)==g)
            FN(g)=FN(g)+1;
        end
    end 
    % precision 
    precision(g) = TP/(TP+FP);
    % recall 
    recall(g) = TP/(TP+FN); 
    % F1 score
    F1Score = 2*((precision(g)*recall(g))/(precision(g)+recall(g)));
end

% average precision and recall value over all gestures
avgPrecision = mean(precision);
avgRecall = mean(recall);

% plot precision and recall averages over increasing amounts of data 
accuracy_all =  [0.6135, 0.703684210526316, 0.785000000000000, 0.790000000000000, 0.786250000000000, 0.830000000000000, 0.834285714285714, 0.856923076923077, 0.830000000000000, ...
0.846363636363636, 0.852000000000000, 0.936666666666667, 0.940000000000000, 0.897142857142857, 0.920000000000000, 0.900000000000000, 0.940000000000000, 0.953333333333333, 0.920000000000000, 0.940000000000000];

precision_all = [0.5994, 0.706711228033525, 0.717267761078340, 0.685159769871033, 0.756842032378332, 0.846540761706795, 0.833356441266895, 0.833674766793886, 0.793460635246770, ...
0.737726888329703, 0.874130448156489, 0.910721388437091, 0.928690139829168, 0.891111093754333, 0.903191819516592, 0.879643041557614, 0.925890909883440, 0.931457050521864, 0.883366740326021, 0.878281452515157 ];

recall_all =    [0.5428, 0.663206140350877, 0.756979276895944, 0.778887721755369, 0.785270833333333, 0.773737566137566, 0.790022675736961, 0.847091880341880, 0.817614748677249, ...
0.852717893217893, 0.829439682539683, 0.930988536155203, 0.936894345238095, 0.861037981859411, 0.905852513227513, 0.869873015873016, 0.933927579365079, 0.935802910052910, 0.880831349206349, 0.914928571428571 ];

F1Score_all =   [0.6074, 0.697195475359878, 0.776921458216573, 0.772019354455202, 0.775922496252693, 0.817063535225099, 0.822013329814348, 0.842373643868021, 0.818234938538656, ... 
0.813579756994580, 0.837466035751945, 0.936117850141561, 0.939470466107403, 0.894002268031071, 0.918376412115682, 0.898559075274682, 0.937658333432240, 0.951034210518200, 0.916067660071345, 0.936522616445267 ];

% figure;
% x = linspace(1,2000,20);
% plot(x,precision_all, 'LineWidth',4)
% hold on
% plot(x,recall_all, 'LineWidth',4)
% legend({'Precision', 'Recall'},'FontSize', 15, 'Position',[0.7 0.2 0.13 0.17])
% xlabel({'Number of Subjects with data included in training','total number of subjects = 21'}, 'FontWeight','bold')
% ylabel({'Percent Precison or Accuracy', '1 = 100%'},'FontWeight','bold')
% title('Precision and Recall as a function of percentage of total data used to train Neural Network','FontSize',20)
% 
% figure; 
% plot(x, accuracy_all, 'LineWidth', 4)
% hold on; 
% plot(x,F1Score_all, 'LineWidth',4)
% legend({'Accuracy', 'F1 Score'},'FontSize', 15, 'Position',[0.7 0.2 0.1 0.2])

figure;  
plot(x,recall_all, 'o-');
hold on;
plot(x,precision_all, '*-')
hold on; 
plot(x,F1Score_all, 's-')
grid on
legend({'Precision', 'Recall', 'F1 Score'},'FontSize', 15, 'Position',[0.7 0.2 0.1 0.2])
xlabel({'# of training samples','total number of subjects = 21'},'FontSize',15)
ylabel({'score', '1 = 100%'},'FontSize',15)
title('Performance Metrics for Neural Network with Increasing # of Training Samples','FontSize',20)

%% plot number of neurons in hidding layer vs % error for testing 
% 
% x=[ 1, 2, 3,4,5,6,7,8,9, 10,15,20,25,30,40,45,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,220,240,260,280,300,320,340,360,380];
% y=[51,35,21,9,9,8,8,9,16,12,10,6,  6, 9, 8, 8, 8, 6, 6, 8, 8,  7,  5,  8, 10,  9,  7,  6,  5,  5,  5,  6,  6,  7,  8,  5,  9, 15,  7, 12, 13];
% 
% plot(x,y,'LineWidth',5);
% title('Percent Accuracy of Neural Network with increasing number of neurons');
% xlabel('Number of Hidden Neurons');
% ylabel('Percent Error');


%% compare males vs females 
% delete the columns of the feature matrix with males 
% featureInputs(:,[1:299, 700:799, 900:1099, 1300:1899, 2000:2100]) = [];

% delete the columns of the target matrix with males 
% targetGestures(:,[1:299, 700:799, 900:1099, 1300:1899, 2000:2100]) = [];

% delete the columns of the feature matrix with females 
% featureInputs(:,[300:699,800:899,1100:1299,1900:1999]) = [];

% delete the columns of the target matrix with females 
% targetGestures(:,[300:699,800:899,1100:1299,1900:1999]) = [];

percent_error_females=[5, 10, 10, 3, 2,8,12,8,8,9] ; 
percent_error_males=[8, 2,8,8,7,11,11,6,9,8];

mean_femaleError = mean(percent_error_females) 
mean_maleError = mean(percent_error_males) 
stdev_femaleError = std(percent_error_females) 
stdev_maleError = std(percent_error_males) 

[h,p]=ttest2(percent_error_females, percent_error_males)

%% compare Germans vs not 

% delete the columns of the feature matrix with Germans  
%featureInputs(:,[1:199, 700:999, 1400:1599, 1900:2000]) = [];

% delete the columns of the target matrix with German  

%targetGestures(:,[1:199, 700:999, 1400:1599, 1900:2000]) = [];

% delete the columns of the feature matrix with nonGermans 
%featureInputs(:,[201:699,1000:1399,1600:1899,2000:2100]) = [];

% delete the columns of the target matrix with non Germans 
% targetGestures(:,[201:699,1000:1399,1600:1899,2000:2100]) = [];

percent_error_nonGermans = [15,8,11,8,6,9,10,9,9,13];
percent_error_Germans = [12,5,18,8,6,6,5,9,6,13];

mean_Germanerror = mean(percent_error_Germans)
mean_nonGermanerror = mean(percent_error_nonGermans)

std_Germanerror = std(percent_error_Germans)
std_nonGermanerror = std(percent_error_nonGermans)

[h,p]=ttest2(percent_error_nonGermans, percent_error_Germans)


